# 实践二
## 网络参数
epoch 400  
隐藏层神经元个数 1024  
learning rate 0.2  
decay rate 0.98  
正则化比例λ 0.01  
激活函数 relu  
损失函数 svm loss  
使用余弦退火+warmup  
## 运行结果
![](pic/Figure_2.png)
![](pic/Figure_1.png)
```bash
result:  
Epoch 399: Loss = 0.2081
Accuracy = 0.9603
Test loss = 0.2226
Test accuracy = 0.9568
``` 
## 尝试过程  
- 损失函数：  尝试使用交叉熵损失，mse损失，svm损失。其中svm损失效果最好。    
- 激活函数：  尝试使用sigmoid，relu。relu收敛速度极快，训练速度快，效果最好。  
- 学习率：    过大模型无法收敛，过小收敛速度较慢，且出现“涌现现象”，即在训练一些epoch后loss突然大幅度下降。  
- decay：     学习率衰减影响不大。  
- 正则化：    使用过大正则化会导致模型无法收敛至最优。  
- hidden neuron size:     过大无明显提升且训练速度大幅度下降，过小最优点效果不佳。

